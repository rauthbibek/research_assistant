# ðŸ”¬ Agentic Research Assistant

A multi-agent research assistant powered by **LangGraph** that researches any topic using web search, blog scraping, and LLM-powered analysis.

## Architecture

```
START â†’ Planner â†’ Researcher â†’ [enough data?] â†’ Analyzer â†’ Writer â†’ END
           â†‘           |
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  (loop if insufficient data)
```

| Agent | Role |
|-------|------|
| **Planner** | Generates sub-questions, search queries, and URLs to scrape |
| **Researcher** | Executes web searches, scrapes blogs, summarizes content |
| **Analyzer** | Synthesizes findings into structured thematic analysis |
| **Writer** | Produces a polished markdown research report with citations |

## Setup

### 1. Create a virtual environment

```bash
python -m venv venv

# Activate it:
# Windows
.\venv\Scripts\activate

# macOS / Linux
source venv/bin/activate
```

### 2. Install dependencies

```bash
pip install -e .
```

### 3. Configure API keys

```bash
cp .env.example .env
# Edit .env and add your API keys
```

**Required:** `OPENAI_API_KEY`  
**Optional:** `TAVILY_API_KEY` (falls back to DuckDuckGo if not set)

### 3. Run

**CLI:**
```bash
python main.py --topic "Your research topic"
python main.py --topic "LLM Agents" --blogs "https://blog1.com,https://blog2.com"
python main.py --topic "RAG techniques" --output my_report.md
```

**Streamlit UI:**
```bash
streamlit run app.py
```

## Project Structure

```
research_assistant/
â”œâ”€â”€ main.py              # CLI entry point
â”œâ”€â”€ app.py               # Streamlit web UI
â”œâ”€â”€ pyproject.toml       # Dependencies
â”œâ”€â”€ .env.example         # API key template
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ state.py         # LangGraph shared state schema
â”‚   â”œâ”€â”€ config.py        # LLM factory & configuration
â”‚   â”œâ”€â”€ graph.py         # LangGraph workflow definition
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ web_search.py    # Tavily / DuckDuckGo search
â”‚   â”‚   â”œâ”€â”€ blog_scraper.py  # URL content extraction
â”‚   â”‚   â””â”€â”€ summarizer.py    # LLM-powered summarization
â”‚   â””â”€â”€ agents/
â”‚       â”œâ”€â”€ planner.py       # Research plan generation
â”‚       â”œâ”€â”€ researcher.py    # Data collection agent
â”‚       â”œâ”€â”€ analyzer.py      # Source analysis agent
â”‚       â””â”€â”€ writer.py        # Report generation agent
â””â”€â”€ output/              # Generated reports
```

## Configuration

| Environment Variable | Default | Description |
|---------------------|---------|-------------|
| `OPENAI_API_KEY` | â€” | OpenAI API key (required) |
| `TAVILY_API_KEY` | â€” | Tavily search API key (optional) |
| `LLM_MODEL` | `gpt-4o-mini` | LLM model to use |
| `LLM_TEMPERATURE` | `0.2` | LLM temperature |
| `MAX_ITERATIONS` | `2` | Max plannerâ†’researcher loops |
| `MAX_SEARCH_RESULTS` | `5` | Results per search query |
| `MAX_SCRAPE_LENGTH` | `8000` | Max chars to extract per page |
