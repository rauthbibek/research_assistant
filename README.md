# ğŸ”¬ Agentic Research Assistant

A multi-agent research assistant powered by **LangGraph** that researches any topic using web search, blog scraping, and LLM-powered analysis.

## Architecture

```mermaid
flowchart LR
    S((Start)) --> P

    subgraph Pipeline
        direction LR
        P[Planner] --> R[Researcher]
        R -- enough data --> A[Analyzer]
        R -- need more --> P
        A --> W[Writer]
    end

    subgraph Tools
        direction TB
        T1[Web Search]
        T2[Blog Scraper]
        T3[Summarizer]
    end

    R -.-> T1
    R -.-> T2
    R -.-> T3

    W --> E((Report))
```

### ğŸ¤– Agents

| Agent | Description |
|-------|-------------|
| **ğŸ“‹ Planner** | Analyzes the topic and generates a research strategy â€” sub-questions to answer, optimized search queries, and URLs to scrape |
| **ğŸ” Researcher** | Executes the plan by running web searches, scraping blog posts, and summarizing long-form content. Loops back to the Planner if data is insufficient (up to N iterations) |
| **ğŸ”¬ Analyzer** | Synthesizes all collected sources into a structured analysis â€” identifies key themes, recurring patterns, contradictions, and knowledge gaps |
| **ğŸ“ Writer** | Transforms the analysis into a polished, publication-ready markdown report with executive summary, detailed findings, and numbered citations |

### ğŸ› ï¸ Tools

| Tool | Description |
|------|-------------|
| **ğŸŒ Web Search** | Searches via [Tavily](https://tavily.com) API; automatically falls back to DuckDuckGo if no API key is set |
| **ğŸ“„ Blog Scraper** | Fetches and extracts main content from any URL using semantic HTML parsing (BeautifulSoup) |
| **âœ‚ï¸ Summarizer** | LLM-powered summarization that condenses long articles while focusing on the research topic |

## Setup

### 1. Create a virtual environment

```bash
python -m venv venv

# Activate it:
# Windows
.\venv\Scripts\activate

# macOS / Linux
source venv/bin/activate
```

### 2. Install dependencies

```bash
pip install -e .
```

### 3. Configure API keys

```bash
cp .env.example .env
# Edit .env and add your API keys
```

**Required:** `OPENAI_API_KEY`  
**Optional:** `TAVILY_API_KEY` (falls back to DuckDuckGo if not set)

### 3. Run

**CLI:**
```bash
python main.py --topic "Your research topic"
python main.py --topic "LLM Agents" --blogs "https://blog1.com,https://blog2.com"
python main.py --topic "RAG techniques" --output my_report.md
```

**Streamlit UI:**
```bash
streamlit run app.py
```

## Project Structure

```
research_assistant/
â”œâ”€â”€ main.py              # CLI entry point
â”œâ”€â”€ app.py               # Streamlit web UI
â”œâ”€â”€ pyproject.toml       # Dependencies
â”œâ”€â”€ .env.example         # API key template
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ state.py         # LangGraph shared state schema
â”‚   â”œâ”€â”€ config.py        # LLM factory & configuration
â”‚   â”œâ”€â”€ graph.py         # LangGraph workflow definition
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ web_search.py    # Tavily / DuckDuckGo search
â”‚   â”‚   â”œâ”€â”€ blog_scraper.py  # URL content extraction
â”‚   â”‚   â””â”€â”€ summarizer.py    # LLM-powered summarization
â”‚   â””â”€â”€ agents/
â”‚       â”œâ”€â”€ planner.py       # Research plan generation
â”‚       â”œâ”€â”€ researcher.py    # Data collection agent
â”‚       â”œâ”€â”€ analyzer.py      # Source analysis agent
â”‚       â””â”€â”€ writer.py        # Report generation agent
â””â”€â”€ output/              # Generated reports
```

## Configuration

| Environment Variable | Default | Description |
|---------------------|---------|-------------|
| `OPENAI_API_KEY` | â€” | OpenAI API key (required) |
| `TAVILY_API_KEY` | â€” | Tavily search API key (optional) |
| `LLM_MODEL` | `gpt-4o-mini` | LLM model to use |
| `LLM_TEMPERATURE` | `0.2` | LLM temperature |
| `MAX_ITERATIONS` | `2` | Max plannerâ†’researcher loops |
| `MAX_SEARCH_RESULTS` | `5` | Results per search query |
| `MAX_SCRAPE_LENGTH` | `8000` | Max chars to extract per page |
